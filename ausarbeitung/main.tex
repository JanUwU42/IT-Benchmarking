\documentclass[12pt,a4paper]{article}

\usepackage{graphicx} % Required for inserting images
\usepackage{geometry}
\usepackage{footmisc}
\usepackage{microtype}
\usepackage{hyperref}


\usepackage{helvet} % Set font to Arial
\renewcommand{\familydefault}{\sfdefault} % Set font to Arial

\usepackage[ngerman]{babel} % German language support

\usepackage
[backend=biber,style=apa,sorting=nyt]{biblatex}
\addbibresource{main.bib}

% Anpassung der Schriftgröße der Fußnoten
\renewcommand{\footnotesize}{\fontsize{10pt}{12pt}\selectfont}

\usepackage{ragged2e} % Text formatting
\justifying % justify text


% Zeilenabstand
\usepackage{setspace}
\setstretch{1.5}

% Seitenabstände
\geometry{
    top=3 cm,
    left=6 cm,
    right=2 cm,
    bottom=2.5 cm,
    headsep=1 cm
}

\graphicspath{ {img/} }

% No indent für ganzes dokument
\setlength\parindent{0pt}


\title{Inwiefern unterscheiden sich n8n-basierte Workflows mit ChatGPT-Agenten und Ollama-Agenten in der Genauigkeit und Effizienz bei der Erkennung von Fake News in Nachrichtenschlagzeilen?
\\ \large Wissenschaftliche Themenarbeit}

\author{Jonas Schierhold, Henning Franzen, Jan Osing}
\date{Januar 2026}

\begin{document}

    \maketitle
    \thispagestyle{empty}

    \begin{center}
        \includegraphics[width=150pt]{img/IHK-Logo.jpg} \includegraphics[width=150pt]{img/WHS-Logo.png}
    \end{center}

    \vfill
    \noindent
    \begin{tabular}{p{4cm}l}
        Matrikelnummern: & \#\#\# \tabularnewline
        Studiengang: & Duales Studium Bachelor of Arts Wirtschaftsinformatik \tabularnewline
        Gruppe: & IT-BW-18 \tabularnewline
        Themensteller: & Prof. Dr. Kruse \tabularnewline
        Abgabedatum: & 27. Februar 2026 \tabularnewline
    \end{tabular}

    \newpage
    \pagenumbering{Roman} % Setzt die Nummerierung auf römnische Zahlen

    \tableofcontents

    \newpage


    \section*{Abkürzungsverzeichnis}

    \noindent
    \begin{tabular}{p{4cm}l}
        WWW & World Wide Web \tabularnewline
        OLLAMA & Omni-Layer Learning Language Acquisition Model \tabularnewline
        KI & Künstliche Intelligenz \tabularnewline
        AI & Artifical intelligence (engl. Künstliche Intelligenz) \tabularnewline
    \end{tabular}

    \newpage
    \pagenumbering{arabic} % Wechsel zur arabischen Nummerierung
    \setcounter{page}{1} % Startet die Nummerierung bei 1
    \setcounter{section}{0} % Setzt den Abschnittszähler auf 0


    \section{Einleitung}
    Seit einigen Jahren verändert sich das Diskussionsklima in Deutschland. Der Umgangston wird rauer, die Meinungen
    polarisieren und die Bereitschaft, einer Position der Gegenseite inhaltlich zuzustimmen, nimmt
    ab.\footnote{\cite[S.~8]{Bertelsmann}.}


    Besonders durch schnelllebige Social Media Formate wie TikTok oder Instagram-Reels ist es einfach geworden,
    Falschaussagen zu verbreiten, um die eigene Position zu stärken.\footnote{\cite[S.~10]{Nim}.} Botnetzwerke verbreiten
    gezielt Posts und Kommentare mit Falschinformationen und Verschwörungsmythen, die von der vermeintlichen Klimalüge
    bis zu extrem verzerrten oder historisch falschen Narrativen reichen.\footnote{\cite{Bsi}.}

    Gleichzeitig nimmt die Nutzung von generativer KI an Fahrt auf. 2025 nutzten 65\% der Befragten einer
    repräsentativen Studie\footnote{\cite{TV-Verband}.} laut eigener Angabe KI regelmäßig. Das ist ein deutliche Anstieg,
    denn zwei Jahre vorher waren es noch 37\%.

    Vor diesem Hintergrund liegt der Einsatz generativer KI zur Überprüfung von Informationen nahe. Dabei stellt sich
    jedoch die Frage nach der Zuverlässigkeit und Effektivität, welche wir im Folgenden bei verschiedenen Modellen
    vergleichen wollen.

    Für den Vergleich werden wir Benchmarking verwenden. Benchmarking ist...


    \section{Technologische Grundlagen}
    \subsection {n8n}
    n8n ist eine Open-Source Workflow-Automatisierungsplattform, mit der digitale Prozesse automatisiert, verknüpft und gesteuert werden können. n8n verfolgt einen Low-Code/No-Code Ansatz, das heißt, dass Nutzende Workflows visuell erstellen können, ohne umfangreiche Programmierkenntnisse zu benötigen. \footnote{\cite{n8n-Workflow-Automation}.}

    n8n bietet eine Vielzahl von vorgefertigten Integrationen (sogenannte "Nodes") für verschiedene Dienste und Anwendungen, darunter auch native Integrationen mit KI-Tools wie ChatGPT und Ollama. Wenn allerdings die vorgefertigten Nodes nicht ausreichen, bietet n8n die Möglichkeit JavaScript oder Python zu verwenden, um benutzerdefinierte Logiken zu implementieren oder auch eigene Nodes zu bauen. \footnote{\cite{n8n-docs}.}

    \subsection{AI-Benchmarking}
    TODO

    \subsection{KI-Agenten}
    TODO

    \subsection{LLM}
    TODO

    \subsection{Ollama  \& Begrenzung eigene Hardware}
    \subsubsection{Ollama}
    Ollama ist ein Open-Source-Tool, das die lokale Bereitstellung und Ausführung von Large Language Models auf eigener Hardware ermöglicht. Das Tool  ist für den Einsatz in Umgebungen mit begrenzten Rechenressourcen sowie für den Offline-Betrieb ausgelegt und erlaubt die Ausführung leistungsfähiger Sprachmodelle ohne Anbindung an externe Cloud-Infrastrukturen. Da die Verarbeitung vollständig lokal erfolgt, verbleiben sämtliche Daten innerhalb der eigenen Systemumgebung. Auf diese Weise können Anforderungen an Datenschutz, Datensouveränität und Vertraulichkeit zuverlässig eingehalten

    \subsubsection{Begrenzung eigene Hardware}
    Die Leistungsfähigkeit der lokalen Ollama LLMs ist begrenzt durch die uns verfügbare Hardware. Insbesondere der verfügbare Arbeitsspeicher (RAM) und die Rechenleistung der CPU/GPU bestimmen, welche Modelle ausgeführt werden können.

    Das Benchmarking wird auf einem Linux System mit dem "6.18.7-2-cachyos" Kernel mit 64 GB DDR5 RAM, einem AMD Ryzen 7 9800X3D Prozessor mit 16 Kernen und 5,2 GHz Taktrate, sowie einer AMD Radeon RX 9070 XT Grafikkarte durchgeführt. Dadurch sind wir in der Lage, relativ leistungsfähige LLMs lokal auszuführen, jedoch sind die Möglichkeiten im Vergleich zu Cloud-basierten eingeschränkt.

    \section{Methodisches Vorgehen}
    \subsection{Auswahl von Kennzahlen zur Evaluierung des Workflows}
    Für die Evaluierung von einem KI-Agenten Workflow stehen eine Vielzahl von Kennzahlen zur Verfügung.\footnote{\cite[S.6062]{KennzahlenAiAgents}.}
    Es werden nur für diese Arbeit relevante Kennzahlen ausgewählt und betrachtet. Ziel der Auswahl der Kennzahlen ist
    es eine Vergleichsgrundlage
    zwischen einem lokalen KI-Agenten mit OLLAMA und einem von OpenAI herzustellen. Hinzu kommt, dass der Workflow als
    ganzes betrachtet wird und auf eine Praxistauglichkeit überprüft wird.
    \newline

    Der KI-Agent wird für diese Arbeit in zwei Dimensionen evaluiert:
    \begin{enumerate}
        \item \textbf{Outputqualität:}
        Effektivität der Aufgabenerfüllung
        \item \textbf{Effizienz:}
        Ressourceneinsatz und Geschwindigkeit
    \end{enumerate}

    Einige Metriken können bei der Evaluierung von KI-Agenten durch eine Schritt-für-Schrittauswertung
    zu oberflächliche und ungenaue Auswertungen führen. Die KI-Agenten können für die gleiche Problemstellung unterschiedliche
    Lösungswege durchführen, welche zum gleichen Ergebniss führen können.  Deshalb wird für die Methodikauswahl die
    Vorgehensweise von \cite[S. 6065ff.]{KennzahlenAiAgents} verwendet. Die Autoren schlagen vor, dass man sich nur die korrekten Schritte
    in der relativen Folge anschaut und diese zur Auswertung verwendet, solange die gleiche relative Schrittreihenfolge
    eingehalten wird.
    Die inkorrekten Schritte werden nicht betrachtet.
    Um für die Praxistauglichkeit eine fundierte Aussage treffen zu können, muss in der Outputqualität die Evaluierung
    der Prozessstabilität (syntaktische Korrektheit) und die inhaltliche Korrektheit (semantische Korrektheit) möglich sein.
    Das wird für diese Arbeit durch die folgenden Metriken definiert: \footnote{\cite[S. 6065f.]{KennzahlenAiAgents}}

    \begin{itemize}
        \item \textbf{Task Completion Ratio:}
        Diese Kennzahl beschreibt den prozentualen Anteil der Aufgaben, die der Agent technisch erfolgreich zu einem Abschluss gebracht hat.

        \item \textbf{Invalid Format:}
        Die Häufigkeit, mit der die Ausgabe des Modells nicht dem gefordertem Schema entspricht.

        \item \textbf{Invalid Action:}
        Die Häufigkeit von Fehlversuche des Agenten, wie etwa den Aufruf nicht existenter Tools oder die Verwendung falscher Parameter.

        \item \textbf{F1-Score:}
        Das harmonische Mittel von Präzision und Recall, um die Zuverlässigkeit eines Modells bei Klassifizierungsaufgaben präzise zu bewerten
    \end{itemize}



    Ergänzend zur Outputqualität wird wie oben beschrieben die Effizienz untersucht. Diese Dimension ist von besonderer
    Relevanz um Unterschiede zwischen der lokalen Hardware-Limitation und den hochverfügbaren KI-Modellen von OpenAI
    quantifizierbar zu machen. Die Metriken sind nicht nur aus technischer Sicht relevant, sondern auch
    aus wirtschaftlicher Sicht. Dadurch kann die fundierte Aussage zur Praxistauglichkeit von mehreren Dimensionen aus
    betrachtet werden, um ein umfassendes Bild zu erzeugen. Für diese Arbeit sind folgende Metriken relevant: \footnote{\cite[S. 6.]{AigenticAiOptimizing}}

    \begin{itemize}
        \item \textbf{End-to-End Latency:\footnote{\cite[S. 2.]{End2EndLatency}}}
        Die Gesamtdauer, die der Workflow von Eingabe der Daten bis zum finalen Ergebniss benötigt.
        \item \textbf{Tokens per Second:\footnote{\cite[S. 2.]{erdil2025inferenceeconomicslanguagemodels}}}
        Die Generierungsgeschwindigkeit des Modells.
        \item \textbf{Token usage:\footnote{\cite[S. 9.]{gendreaudistler2025automatinghighenergyphysics}}}
        Die Gesamtzahl an verbrauchten Tokens für einen Input-Output Durchlauf.
        \item \textbf{Kosten pro Workflowdurchlauf:}
        Die Kosten für die Durchführung einer Überprüfung
    \end{itemize}

    Die Resultate der Kennzahlen werden als arithmetisches Mittel der Kennzahlen dargestellt. Zu jedem Mittelwert wird
    auch die Standardabweichung angegeben.

    \subsection{Auwsahl eines Datensatzes}
    Zum Testen des Workflows wird ein öffentlicher Datensatz von Kaggle\footnote{\url{https://www.kaggle.com}.} ausgewählt. Die
    Qualität des Datensatzes ist von entscheidender Relevanz. Um eine realistische Evaluation machen zu können müssen
    die Daten korrekt und in ausreichender Menge verfügbar sein. Außerdem muss eine Zuordnung zu Wahr oder Falsch eindeutig machbar sein.
    Ferner muss eine eindeutige zeitliche Einordnung möglich sein, weil lokale OLLAMA Modelle meist mit veralteten Daten trainiert sind und
    somit das KI-Modell von OpenAI einen Vorteil hat. Die Qualität des Datensatzes wird direkt von Kaggle bestimmt. Es gibt
    einen Usability Score, welcher unter anderem das die Vorgehensweise und Quellen für die Erstellung des Datensatzes überprüft.
    Nichtsdestotrotz muss der Herausgebende des Datensatzes überprüft werden und auf die Vertrauenswürdigkeit überprüft werden.
    \newline
    Für diese Arbeit wurde der folgende \href{https://www.kaggle.com/datasets/bhavikjikadara/fake-news-detection}{Datensatz} von Bhavik Jikadara verwendet.


    \subsection{Versuchsaufbau}
     Hier beschreiben, wie Daten in n8n reinkommen.
     Lokale Hardware Limitation , also Stichproben durchführen.
     Abstrahiertes Prozessdiagramm erstellen


    \section{Prototypische Implementierung}
    Die prototypische Implementierung erfolgt anhand der theoretischen Grundlagen, die in dem vorherigen Kapitel beschrieben wurden.


    \section{Auswertung}
    Hier kommt die Beschreibung und Auswertung.


    \section{Fazit}
    Hier kommt das Fazit.

    \newpage

    \pagenumbering{Roman} % Setzt die Nummerierung auf römnische Zahlen
    \setcounter{page}{3} % Setzt die Nummerierung auf 3

    \printbibliography


\end{document}

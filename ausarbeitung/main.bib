%! Author = 10114915
%! Date = 27.01.2026

@article{TEST,
    author = "Henning",
    title = "A Title",
    journal = "My Journal",
    year = "2000",
}

@report{Bertelsmann,
    author = "Lukas Bernhard and Leonie Schulz and Cathleen Berger and Kai Unzicker",
    title = "Verunsicherte Öffentlichkeit",
    institution = "Bertelsmann Stiftung",
    year = "2024",
    type = "Studie",
}

@report{Nim,
    author = "Tobias Biró",
    title = "Zwischen Wahrheit und Lüge. Wie die Gesellschaft Fake News wahrnimmt und wie sie damit umgeht",
    type = "Studie",
    institution = "Nuremberg Institute for Market Decisions",
    year = "2024"
}

@misc{TV-Verband,
    author = "TÜV-Verband",
    institution = "Forsa",
    title = "KI-Studie 2025: Generative KI wird zum Massenphänomen – aber Sicherheit und Orientierung fehlen",
    year = "2025",
    url = "https://www.tuev-verband.de/studien/chatgpt-studie-2025-generative-ki-wird-zum-massenphaenomen-aber-sicherheit-und-orientierung-fehlen",
    urldate = "2026-01-27",
}

@misc{Bsi,
    author= "{Bundesamt für Sicherheit in der Informationstechnik}",
    title = "Desinformation im Internet",
    year = "2026",
    url = "https://www.bsi.bund.de/DE/Themen/Verbraucherinnen-und-Verbraucher/Informationen-und-Empfehlungen/Onlinekommunikation/Soziale-Netzwerke/Sichere-Verwendung/Desinformation/desinformation_node.html",
    urldate = "2026-01-27",
}

@inproceedings{KennzahlenAiAgents,
    author = {Xing, Mingzhe and Zhang, Rongkai and Xue, Hui and Chen, Qi and Yang, Fan and Xiao, Zhen},
    title = {Understanding the Weakness of Large Language Model Agents within a Complex Android Environment},
    year = {2024},
    isbn = {9798400704901},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3637528.3671650},
    doi = {10.1145/3637528.3671650},
    abstract = {Large language models (LLMs) have empowered intelligent agents to execute intricate tasks within domain-specific software such as browsers and games. However, when applied to general-purpose software systems like operating systems, LLM agents face three primary challenges. Firstly, the action space is vast and dynamic, posing difficulties for LLM agents to maintain an up-to-date understanding and deliver accurate responses. Secondly, real-world tasks often require inter-application cooperation, demanding farsighted planning from LLM agents. Thirdly, agents need to identify optimal solutions aligning with user constraints, such as security concerns and preferences. These challenges motivate AndroidArena, an environment and benchmark designed to evaluate LLM agents on a modern operating system. To address high-cost of manpower, we design a scalable and semi-automated method to construct the benchmark. In the task evaluation, AndroidArena incorporates accurate and adaptive metrics to address the issue of non-unique solutions. Our findings reveal that even state-of-the-art LLM agents struggle in cross-APP scenarios and adhering to specific constraints. Additionally, we identify a lack of four key capabilities, i.e. understanding, reasoning, exploration, and reflection, as primary reasons for the failure of LLM agents. Furthermore, we provide empirical analysis on the failure of reflection, and improve the success rate by 27\% with our proposed exploration strategy. This work is the first to present valuable insights in understanding fine-grained weakness of LLM agents, and offers a path forward for future research in this area. Environment, benchmark, prompt, and evaluation code for AndroidArena are released at https://github.com/AndroidArenaAgent/AndroidArena.},
    booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
    pages = {6061–6072},
    numpages = {12},
    keywords = {ai agent, large language model, task planning},
    location = {Barcelona, Spain},
    series = {KDD '24}
}

@misc{AigenticAiOptimizing,
    title={Optimizing Agentic Workflows using Meta-tools},
    author={Sami Abuzakuk and Anne-Marie Kermarrec and Rishi Sharma and Rasmus Moorits Veski and Martijn de Vos},
    year={2026},
    eprint={2601.22037},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2601.22037},
}

@misc{End2EndLatency,
    title={On Evaluating Performance of LLM Inference Serving Systems},
    author={Amey Agrawal and Nitin Kedia and Anmol Agarwal and Jayashree Mohan and Nipun Kwatra and Souvik Kundu and Ramachandran Ramjee and Alexey Tumanov},
    year={2025},
    eprint={2507.09019},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2507.09019},
}

@misc{erdil2025inferenceeconomicslanguagemodels,
    title={Inference economics of language models},
    author={Ege Erdil},
    year={2025},
    eprint={2506.04645},
    archivePrefix={arXiv},
    primaryClass={cs.LG},
    url={https://arxiv.org/abs/2506.04645},
}

@misc{gendreaudistler2025automatinghighenergyphysics,
    title={Automating High Energy Physics Data Analysis with LLM-Powered Agents},
    author={Eli Gendreau-Distler and Joshua Ho and Dongwon Kim and Luc Tomas Le Pottier and Haichen Wang and Chengxi Yang},
    year={2025},
    eprint={2512.07785},
    archivePrefix={arXiv},
    primaryClass={physics.data-an},
    url={https://arxiv.org/abs/2512.07785},
}

// Kann interessant sein für LLM lokale Kosten
@misc{pan2025costbenefitanalysisonpremiselarge,
    title={A Cost-Benefit Analysis of On-Premise Large Language Model Deployment: Breaking Even with Commercial LLM Services},
    author={Guanzhong Pan and Vishal Chodnekar and Abinas Roy and Haibo Wang},
    year={2025},
    eprint={2509.18101},
    archivePrefix={arXiv},
    primaryClass={cs.AI},
    url={https://arxiv.org/abs/2509.18101},
}